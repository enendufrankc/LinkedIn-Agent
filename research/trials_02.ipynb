{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkedIn Influencer Project Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scrape LinkedIn Post: This Scrape AI Training Data From LinkedIn Profile for post Personalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\LENOVO\\\\1. Projects\\\\LinkedIn Agent\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\LENOVO\\\\1. Projects\\\\LinkedIn Agent'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Linked Scraper tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from crewai_tools import tool\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Config:\n",
    "#     \"\"\"\n",
    "#     A configuration class that fetches environment variables.\n",
    "#     \"\"\"\n",
    "#     OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#     MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "#     SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "#     LINKEDIN_EMAIL = os.getenv(\"LINKEDIN_EMAIL\")\n",
    "#     LINKEDIN_PASSWORD = os.getenv(\"LINKEDIN_PASSWORD\")\n",
    "#     LINKEDIN_PROFILE_NAME = os.getenv(\"LINKEDIN_PROFILE_NAME\")\n",
    "    \n",
    "#     ACCESS_TOKEN = os.getenv(\"ACCESS_TOKEN\")\n",
    "\n",
    "from config.configuration import Config\n",
    "\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: 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\n",
      "MISTRAL_API_KEY: kDWKAodSgm2igkH7UsyCJVThWaLkAi9B\n",
      "SERPER_API_KEY: 14f942a8aa37ed120a00d66653a2e6da7bf74d0c\n",
      "LINKEDIN_EMAIL: enendufrankc@gmail.com\n",
      "LINKEDIN_PASSWORD: Ceuf352160$$\n",
      "LINKEDIN_PROFILE_NAME: enendu-frank-chinedu\n",
      "ACCESS_TOKEN: AQXVuXnRIY5U2c_iVHhJRvaclhw-9_zVWxvvZpV6wn1t8NqgO7q0ODALcbAQ8g6ey3wkuoWEP8-XtCGtr6nRLRkqBjd7GmmxJJWz4yByYiablWEjkDWxjbJNpQ4o-PbltZrOi5fc1gnLcW6XRNQL6YoovkuN_pxtKvCkAsZ3HhnUr12lN9JgtPFXOtUpXvI7_mtVQomQw30ZmqfwtJWf1w4dYt2c7BNPanSDeCRhyqxDsRzGYCdZt9-O3X6Xy9ZUpl_CZRO23sWDJmYqLsRqk5b8QRFiDXaxCmrn997kzAup2vZXZnTr6P2Y1cb3_koq5DM1hTkTZBQHghgq6d2IJb5Xwj4IWg\n"
     ]
    }
   ],
   "source": [
    "# Test if environment variables are loaded correctly\n",
    "print(\"OPENAI_API_KEY:\", Config.OPENAI_API_KEY)\n",
    "print(\"MISTRAL_API_KEY:\", Config.MISTRAL_API_KEY)\n",
    "print(\"SERPER_API_KEY:\", Config.SERPER_API_KEY)\n",
    "print(\"LINKEDIN_EMAIL:\", Config.LINKEDIN_EMAIL)\n",
    "print(\"LINKEDIN_PASSWORD:\", Config.LINKEDIN_PASSWORD)\n",
    "print(\"LINKEDIN_PROFILE_NAME:\", Config.LINKEDIN_PROFILE_NAME)\n",
    "print(\"ACCESS_TOKEN:\", Config.ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html_content(page_source: str):\n",
    "    \"\"\"\n",
    "    Parses the page source HTML of a LinkedIn profile and filters \n",
    "    the containers that contain post information.\n",
    "    \"\"\"\n",
    "    linkedin_soup = BeautifulSoup(page_source.encode(\"utf-8\"), \"lxml\")\n",
    "    containers = linkedin_soup.find_all(\"div\", {\"class\": \"feed-shared-update-v2\"})\n",
    "    containers = [container for container in containers \n",
    "                  if 'activity' in container.get('data-urn', '')]\n",
    "    return containers\n",
    "\n",
    "def get_post_content(container, selector, attributes):\n",
    "    \"\"\"\n",
    "    Retrieves the text content from a specific HTML element \n",
    "    within a container.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        element = container.find(selector, attributes)\n",
    "        if element:\n",
    "            return element.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting post content: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "def get_linkedin_posts(page_source: str):\n",
    "    \"\"\"\n",
    "    Uses parse_html_content to identify relevant containers, then \n",
    "    extracts the post text from each container.\n",
    "    \"\"\"\n",
    "    containers = parse_html_content(page_source)\n",
    "    posts = []\n",
    "    for container in containers:\n",
    "        post_content = get_post_content(container, \"div\", {\"class\": \"update-components-text\"})\n",
    "        posts.append(post_content)\n",
    "    return posts\n",
    "\n",
    "\n",
    "# from src.linkedIn_agent.utils.common import parse_html_content, get_post_content, get_linkedin_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedinToolException(Exception):\n",
    "    \"\"\"\n",
    "    Custom exception used when LinkedIn credentials are not provided in env variables.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(\"You need to set the LINKEDIN_EMAIL and LINKEDIN_PASSWORD env variables\")\n",
    "        \n",
    "\n",
    "def scrape_linkedin_posts_fn() -> str:\n",
    "    \"\"\"\n",
    "    A function that logs into LinkedIn using credentials from environment \n",
    "    variables, scrolls through a profile's posts, and returns the posts.\n",
    "    \"\"\"\n",
    "    linkedin_username = os.environ.get(\"LINKEDIN_EMAIL\")\n",
    "    linkedin_password = os.environ.get(\"LINKEDIN_PASSWORD\")\n",
    "    linkedin_profile_name = os.environ.get(\"LINKEDIN_PROFILE_NAME\")\n",
    "\n",
    "    if not (linkedin_username and linkedin_password):\n",
    "        raise LinkedinToolException()\n",
    "\n",
    "    # Initialize WebDriver (make sure chromedriver is installed and in PATH)\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://www.linkedin.com/login\")\n",
    "\n",
    "    # Perform login\n",
    "    username_input = browser.find_element(\"id\", \"username\")\n",
    "    password_input = browser.find_element(\"id\", \"password\")\n",
    "    username_input.send_keys(linkedin_username)\n",
    "    password_input.send_keys(linkedin_password)\n",
    "    password_input.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Wait for page to load\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Navigate to the profile's \"Recent Activity\"\n",
    "    browser.get(f\"https://www.linkedin.com/in/{linkedin_profile_name}/recent-activity/all/\")\n",
    "\n",
    "    # Scroll to load more posts\n",
    "    for _ in range(2):\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    # Extract posts\n",
    "    posts = get_linkedin_posts(browser.page_source)\n",
    "    browser.quit()\n",
    "    return str(posts[:5])\n",
    "\n",
    "@tool(\"ScrapeLinkedinPosts\")\n",
    "def scrape_linkedin_posts_tool() -> str:\n",
    "    \"\"\"\n",
    "    A tool that can be used to scrape LinkedIn posts.\n",
    "    \"\"\"\n",
    "    return scrape_linkedin_posts_fn()\n",
    "\n",
    "\n",
    "# from src.linkedIn_agent.tools.linkedIn_scraper import scrape_linkedin_posts_fn, scrape_linkedin_posts_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posts = scrape_linkedin_posts_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\1. Projects\\LinkedIn Agent\\env\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:775: UserWarning: Mixing V1 models and V2 models (or constructs, like `TypeAdapter`) is not supported. Please upgrade `CrewAgentExecutor` to V2.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from textwrap import dedent\n",
    "from crewai import Task\n",
    "from crewai import Agent\n",
    "from crewai_tools import ScrapeWebsiteTool, SerperDevTool\n",
    "from src.linkedIn_agent.tools.linkedIn_scraper import scrape_linkedin_posts_tool\n",
    "\n",
    "# If you have these custom modules:\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Get LLM API Keys from Config\n",
    "# openai_key = Config.OPENAI_API_KEY\n",
    "# mistral_key = Config.MISTRAL_API_KEY\n",
    "\n",
    "openai_llm = ChatOpenAI(api_key=Config.OPENAI_API_KEY, model=\"gpt-3.5-turbo-0125\")\n",
    "mistral_llm = ChatMistralAI(api_key=os.environ.get(\"MISTRAL_API_KEY\"), model=\"mistral-large-latest\", streaming=False)\n",
    "\n",
    "# Initialize other tools\n",
    "scrape_website_tool = ScrapeWebsiteTool()\n",
    "search_tool = SerperDevTool()\n",
    "\n",
    "# Define the LinkedIn scraper agent\n",
    "linkedin_scraper_agent = Agent(\n",
    "    role=\"LinkedIn Post Scraper\",\n",
    "    goal=\"Your goal is to scrape a LinkedIn profile to get a list of posts from the given profile\",\n",
    "    tools=[scrape_linkedin_posts_tool],\n",
    "    backstory=dedent(\n",
    "        \"\"\"\n",
    "        You are an experienced programmer who excels at web scraping.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=openai_llm\n",
    ")\n",
    "\n",
    "# Define the scraping task\n",
    "scrape_linkedin_task = Task(\n",
    "    description=dedent(\n",
    "        \"Scrape a LinkedIn profile to get some relevant posts\"\n",
    "    ),\n",
    "    expected_output=dedent(\n",
    "        \"A list of LinkedIn posts obtained from a LinkedIn profile\"\n",
    "    ),\n",
    "    agent=linkedin_scraper_agent,\n",
    ")\n",
    "\n",
    "# Define the web researcher agent\n",
    "web_researcher_agent = Agent(\n",
    "    role=\"Web Researcher\",\n",
    "    goal=\"Your goal is to search for relevant content about the comparison between Llama 2 and Llama 3\",\n",
    "    tools=[scrape_website_tool, search_tool],\n",
    "    backstory=dedent(\n",
    "        \"\"\"\n",
    "        You are proficient at searching for specific topics on the web, \n",
    "        selecting those that provide more value and information.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=openai_llm\n",
    ")\n",
    "\n",
    "# Define the web research task\n",
    "web_research_task = Task(\n",
    "    description=dedent(\n",
    "        \"Get valuable and high quality web information about the comparison between Llama 2 and Llama 3\"\n",
    "    ),\n",
    "    expected_output=dedent(\n",
    "        \"Your task is to gather high quality information about the comparison between Llama 2 and Llama 3\"\n",
    "    ),\n",
    "    agent=web_researcher_agent,\n",
    ")\n",
    "\n",
    "# Define the doppelganger agent\n",
    "doppelganger_agent = Agent(\n",
    "    role=\"LinkedIn Post Creator\",\n",
    "    goal=\"You will create a LinkedIn post comparing Llama 2 and Llama 3 following the writing style observed in the LinkedIn posts scraped by the LinkedIn Post Scraper.\",\n",
    "    backstory=dedent(\n",
    "        \"\"\"\n",
    "        You are an expert in writing LinkedIn posts replicating any influencer style.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=openai_llm\n",
    ")\n",
    "\n",
    "# Define the final post creation task\n",
    "create_linkedin_post_task = Task(\n",
    "    description=dedent(\n",
    "        \"Create a LinkedIn post comparing Llama 2 and Llama 3 following the writing-style expressed in the scraped LinkedIn posts.\"\n",
    "    ),\n",
    "    expected_output=dedent(\n",
    "        \"A high-quality and engaging LinkedIn post comparing Llama 2 and Llama 3. \"\n",
    "        \"The LinkedIn post must follow the same writing-style as the one expressed in the scraped LinkedIn posts.\"\n",
    "    ),\n",
    "    agent=doppelganger_agent,\n",
    ")\n",
    "\n",
    "# Provide context to the final post creation task\n",
    "create_linkedin_post_task.context = [scrape_linkedin_task, web_research_task]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the ScrapeLinkedinPosts tool to scrape the LinkedIn profile for relevant posts.\n",
      "\n",
      "Action: ScrapeLinkedinPosts\n",
      "Action Input: {\"profile\": \"JohnDoeLinkedInProfile\"}\u001b[0m\u001b[95m \n",
      "\n",
      "['DeepSeek R1 is now available in the model catalog on\\xa0Azure AI Foundry\\xa0and GitHub, joining a diverse portfolio of over 1,800 models, including frontier, open-source, industry-specific, and task-based AI models.', \"The Hugging Face course on AI agents focuses on fundamentals not frameworks. We build up from a solid understanding of the ReAct framework.ðŸ‘‰ the course is FREE sign up here: https://lnkd.in/eUYUzHBSThe ReAct framework is continuous loop that drives the agent's learning and adaptation:Thoughts are the agent's modelâ€™s internal reasoning process. It's where the model analyzes information, makes decisions, and formulating plans.Actions are how the agent interacts with its environment. This could be anything from browsing the web, calling an API, to controlling a robot in the real world.Observations are the feedback the agent receives from its actions and the changes in its environment. It's how the agent learns and adapts.This cycle makes AI agents adaptable by evolving.I'm super excited to be prepping for our upcoming course on AI agents! ðŸ¤“ As I dig into the material, I'm amazed by how useful agents are to use cases.\"]\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mFinal Answer: \n",
      "\n",
      "['DeepSeek R1 is now available in the model catalog on\\xa0Azure AI Foundry\\xa0and GitHub, joining a diverse portfolio of over 1,800 models, including frontier, open-source, industry-specific, and task-based AI models.', \"The Hugging Face course on AI agents focuses on fundamentals not frameworks. We build up from a solid understanding of the ReAct framework.ðŸ‘‰ the course is FREE sign up here: https://lnkd.in/eUYUzHBSThe ReAct framework is continuous loop that drives the agent's learning and adaptation:Thoughts are the agent's modelâ€™s internal reasoning process. It's where the model analyzes information, makes decisions, and formulating plans.Actions are how the agent interacts with its environment. This could be anything from browsing the web, calling an API, to controlling a robot in the real world.Observations are the feedback the agent receives from its actions and the changes in its environment. It's how the agent learns and adapts.This cycle makes AI agents adaptable by evolving.I'm super excited to be prepping for our upcoming course on AI agents! ðŸ¤“ As I dig into the material, I'm amazed by how useful agents are to use cases.\"]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to search for relevant content comparing Llama 2 and Llama 3 using the tools available to me.\n",
      "\n",
      "Action: Search the internet\n",
      "Action Input: {\"search_query\": \"Comparison between Llama 2 and Llama 3\"}\u001b[0m\u001b[95m \n",
      "\n",
      "\n",
      "Search results: Title: Llama 2 vs Llama 3: An In-depth Comparison - Medium\n",
      "Link: https://medium.com/@vineethveetil/llama-2-vs-llama-3-an-in-depth-comparison-aebb6a3f8c51\n",
      "Snippet: Llama 2 uses SentencePiece for tokenization, whereas Llama 3 has transitioned to OpenAI's Tiktoken. Llama 3 also introduces a ChatFormat class, ...\n",
      "---\n",
      "Title: Llama 3 vs Llama 2. Comparison, Differences, Features | Apps4Rent\n",
      "Link: https://www.apps4rent.com/blog/llama-3-vs-llama-2/\n",
      "Snippet: Llama 3 has made some big improvements compared to Llama 2. Llama 3 8B contains 8 billion parameters and Llama 3 70B contains 70 billion parameters.\n",
      "---\n",
      "Title: LLaMa 3 vs LLaMa 2 - Analyzing the Difference. - MonsterAPI Blog\n",
      "Link: https://blog.monsterapi.ai/blogs/what-is-llama-3-and-how-it-differs-from-llama-2/\n",
      "Snippet: LLaMa 3 boasts better performance across all parameters compared to LLaMa 2. Here's the comparison: Enhanced Performance: LLaMa 3 tackles multi- ...\n",
      "---\n",
      "Title: Meta's Llama 2 Vs Llama 3: What's New and Why It Matters - Kanerika\n",
      "Link: https://kanerika.com/blogs/llama-3-vs-llama-2/\n",
      "Snippet: Llama 3 is often more efficient than Llama 2, requiring fewer computational resources to achieve similar results. While both models can be run ...\n",
      "---\n",
      "Title: Introducing Meta Llama 3: The most capable openly available LLM ...\n",
      "Link: https://ai.meta.com/blog/meta-llama-3/\n",
      "Snippet: Our new 8B and 70B parameter Llama 3 models are a major leap over Llama 2 and establish a new state-of-the-art for LLM models at those scales.\n",
      "---\n",
      "Title: Result: Llama 3 EXL2 quant quality compared to GGUF and Llama 2\n",
      "Link: https://www.reddit.com/r/LocalLLaMA/comments/1cfbadc/result_llama_3_exl2_quant_quality_compared_to/\n",
      "Snippet: The quality at same model size seems to be exactly the same between EXL2 and the latest imatrix IQ quants of GGUF, for both Llama 3 and 2.\n",
      "---\n",
      "Title: Differences Between LLAMA 2 and LLAMA 3 - LinkedIn\n",
      "Link: https://www.linkedin.com/pulse/differences-between-llama-2-3-blockchaincouncil-to3jc\n",
      "Snippet: LLAMA 3 features a more efficient tokenizer with a vocabulary size of 128K tokens, compared to LLAMA 2's smaller tokenizer. This improvement ...\n",
      "---\n",
      "Title: I'd Rather have Llama-2 with 65K+ Context Size than Llama-3 or ...\n",
      "Link: https://www.reddit.com/r/LocalLLaMA/comments/1dq5lia/id_rather_have_llama2_with_65k_context_size_than/\n",
      "Snippet: LLaMa had a context length of 2048, then Llama-2 had 4096, now Llama-3 has 8192. Fine tuning with RoPE scaling is a lot cheaper and less ...\n",
      "---\n",
      "Title: Llama 2 vs Llama 3: Key AI Model Comparisons & Insights\n",
      "Link: https://www.neuronimbus.com/blog/a-comparative-analysis-and-the-ultimate-comparison-of-all-large-language-models/\n",
      "Snippet: Llama 2 vs Llama 3 â€“ Key Differences Â· Long-form document processing Â· Multi-step reasoning and problem-solving Â· Extended conversations.\n",
      "---\n",
      "Title: What is Meta's Llama 3 and comparison with llama 2? - Hamid Ayub\n",
      "Link: https://hamidayub.medium.com/what-is-metas-llama-3-and-comparison-with-llama-2-0de992430e3c\n",
      "Snippet: This article explores the enhancements introduced with Llama 3, its impact on various sectors, and provides a detailed comparison with Llama 2.\n",
      "---\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mFinal Answer: \n",
      "Llama 2 vs Llama 3: An In-depth Comparison - Medium\n",
      "\n",
      "Llama 2 uses SentencePiece for tokenization, whereas Llama 3 has transitioned to OpenAI's Tiktoken. Llama 3 also introduces a ChatFormat class\n",
      "\n",
      "Llama 3 vs Llama 2. Comparison, Differences, Features | Apps4Rent\n",
      "\n",
      "Llama 3 has made some big improvements compared to Llama 2. Llama 3 8B contains 8 billion parameters and Llama 3 70B contains 70 billion parameters.\n",
      "\n",
      "LLaMa 3 vs LLaMa 2 - Analyzing the Difference. - MonsterAPI Blog\n",
      "\n",
      "LLaMa 3 boasts better performance across all parameters compared to LLaMa 2. Enhanced Performance: LLaMa 3 tackles multi-\n",
      "\n",
      "Meta's Llama 2 Vs Llama 3: What's New and Why It Matters - Kanerika\n",
      "\n",
      "Llama 3 is often more efficient than Llama 2, requiring fewer computational resources to achieve similar results.\n",
      "\n",
      "Introducing Meta Llama 3: The most capable openly available LLM\n",
      "\n",
      "Our new 8B and 70B parameter Llama 3 models are a major leap over Llama 2 and establish a new state-of-the-art for LLM models at those scales.\n",
      "\n",
      "Result: Llama 3 EXL2 quant quality compared to GGUF and Llama 2\n",
      "\n",
      "The quality at same model size seems to be exactly the same between EXL2 and the latest imatrix IQ quants of GGUF, for both Llama 3 and 2.\n",
      "\n",
      "Differences Between LLAMA 2 and LLAMA 3 - LinkedIn\n",
      "\n",
      "LLAMA 3 features a more efficient tokenizer with a vocabulary size of 128K tokens, compared to LLAMA 2's smaller tokenizer.\n",
      "\n",
      "I'd Rather have Llama-2 with 65K+ Context Size than Llama-3 or ...\n",
      "\n",
      "LLaMa had a context length of 2048, then Llama-2 had 4096, now Llama-3 has 8192. Fine tuning with RoPE scaling is a lot cheaper and less\n",
      "\n",
      "Llama 2 vs Llama 3: Key AI Model Comparisons & Insights\n",
      "\n",
      "Llama 2 vs Llama 3 â€“ Key Differences Â· Long-form document processing Â· Multi-step reasoning and problem-solving Â· Extended conversations.\n",
      "\n",
      "What is Meta's Llama 3 and comparison with llama 2? - Hamid Ayub\n",
      "\n",
      "This article explores the enhancements introduced with Llama 3, its impact on various sectors, and provides a detailed comparison with Llama 2.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAfter carefully analyzing the various comparisons between Llama 2 and Llama 3, it is evident that Llama 3 has significantly advanced in terms of parameters, performance, and efficiency compared to Llama 2. The transition to OpenAI's Tiktoken in Llama 3, along with the introduction of the ChatFormat class, showcases a major leap in the development of LLM models.\n",
      "\n",
      "Final Answer:\n",
      "Llama 3 has truly raised the bar with its 8 billion and 70 billion parameter models, establishing a new state-of-the-art for LLM models. The improved performance and efficiency of Llama 3 make it a compelling choice over Llama 2 for various AI applications. The advancements in tokenization and vocabulary size further highlight the superiority of Llama 3 in the realm of AI model development. It is clear that Llama 3 is paving the way for more capable and adaptable AI models, making it a game-changer in the industry.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from crewai import Crew\n",
    "\n",
    "# Create a Crew of agents and tasks\n",
    "crew = Crew(\n",
    "    agents=[\n",
    "        linkedin_scraper_agent,\n",
    "        web_researcher_agent,\n",
    "        doppelganger_agent,\n",
    "    ],\n",
    "    tasks=[\n",
    "        scrape_linkedin_task,\n",
    "        web_research_task,\n",
    "        create_linkedin_post_task,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Kick off the pipeline\n",
    "result = crew.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the result: \n",
      "Llama 3 has truly raised the bar with its 8 billion and 70 billion parameter models, establishing a new state-of-the-art for LLM models. The improved performance and efficiency of Llama 3 make it a compelling choice over Llama 2 for various AI applications. The advancements in tokenization and vocabulary size further highlight the superiority of Llama 3 in the realm of AI model development. It is clear that Llama 3 is paving the way for more capable and adaptable AI models, making it a game-changer in the industry.\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is the result: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (1.41.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.24.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\1. projects\\linkedin agent\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
